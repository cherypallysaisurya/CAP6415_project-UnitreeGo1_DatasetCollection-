{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb086652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and extract dataset\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"Please upload dataset_v2.zip...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract\n",
    "with zipfile.ZipFile('dataset_v2.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/')\n",
    "\n",
    "print(\"\\nExtracted contents:\")\n",
    "!ls -la /content/dataset_v2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e467096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = Path(\"/content/dataset_v2\")\n",
    "\n",
    "TRAIN_SESSIONS = [\n",
    "    \"4th_floor_hallway_20251206_132136\",\n",
    "    \"4th_floor_lounge_20251206_154822\",\n",
    "    \"5th_floor_hallway_20251206_161536\",\n",
    "    \"3rd_floor_hallway_20251206_162223\",\n",
    "]\n",
    "\n",
    "TEST_SESSIONS = [\n",
    "    \"Mlab_20251207_112819\",\n",
    "]\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e285ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class CameraLiDARDataset(Dataset):\n",
    "    \"\"\"Dataset that pairs camera images with LiDAR-derived targets.\"\"\"\n",
    "\n",
    "    def __init__(self, sessions, data_dir, transform=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        for session in sessions:\n",
    "            session_dir = self.data_dir / session\n",
    "            image_dir = session_dir / \"frames\"\n",
    "            velodyne_dir = session_dir / \"velodyne\"\n",
    "\n",
    "            if not image_dir.exists() or not velodyne_dir.exists():\n",
    "                print(f\"  Warning: Missing data in {session}\")\n",
    "                continue\n",
    "\n",
    "            image_files = sorted(image_dir.glob(\"*.png\"))\n",
    "\n",
    "            for img_path in image_files:\n",
    "                frame_id = img_path.stem\n",
    "                lidar_path = velodyne_dir / f\"{frame_id}.bin\"\n",
    "\n",
    "                if lidar_path.exists():\n",
    "                    points = np.fromfile(str(lidar_path), dtype=np.float32).reshape(-1, 5)\n",
    "                    x, y, z = points[:, 0], points[:, 1], points[:, 2]\n",
    "                    mean_distance = np.sqrt(x**2 + y**2 + z**2).mean()\n",
    "                    self.samples.append((img_path, mean_distance))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, target = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(target, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8065f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class\n",
    "class ResNetRegressor(nn.Module):\n",
    "    \"\"\"ResNet18 modified for regression.\"\"\"\n",
    "\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNetRegressor, self).__init__()\n",
    "        self.resnet = models.resnet18(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, targets in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    all_preds, all_targets = np.array(all_preds), np.array(all_targets)\n",
    "    mae = np.abs(all_preds - all_targets).mean()\n",
    "    rmse = np.sqrt(((all_preds - all_targets) ** 2).mean())\n",
    "    ss_res = ((all_targets - all_preds) ** 2).sum()\n",
    "    ss_tot = ((all_targets - all_targets.mean()) ** 2).sum()\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "\n",
    "    return {'loss': total_loss / len(dataloader), 'mae': mae, 'rmse': rmse, 'r2': r2,\n",
    "            'predictions': all_preds, 'targets': all_targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c08837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = CameraLiDARDataset(TRAIN_SESSIONS, DATA_DIR, transform=train_transform)\n",
    "test_dataset = CameraLiDARDataset(TEST_SESSIONS, DATA_DIR, transform=test_transform)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d18230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample images\n",
    "print(\"\\nðŸ“· Sample Camera Images with LiDAR Distances:\")\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(train_dataset):\n",
    "        img_path, dist = train_dataset.samples[i * 100]  # Sample every 100th\n",
    "        img = Image.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Distance: {dist:.2f}m\", fontsize=10)\n",
    "        ax.axis('off')\n",
    "plt.suptitle(\"Sample Training Images with Ground Truth LiDAR Distances\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcda599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "print(\"\\nðŸ§  Creating ResNet18 Model...\")\n",
    "model = ResNetRegressor(pretrained=True).to(device)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61304b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(f\"\\nðŸš€ Training for {NUM_EPOCHS} epochs...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_losses, val_losses, val_maes = [], [], []\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_results = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_results['loss'])\n",
    "    val_maes.append(val_results['mae'])\n",
    "\n",
    "    print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_results['loss']:.4f} | Val MAE: {val_results['mae']:.4f}m\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nâœ… Training completed in {total_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "print(\"\\nðŸ“Š Final Evaluation on Test Set...\")\n",
    "final_results = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"TEST RESULTS\")\n",
    "print(f\"{'='*40}\")\n",
    "print(f\"  MAE:  {final_results['mae']:.4f} meters\")\n",
    "print(f\"  RMSE: {final_results['rmse']:.4f} meters\")\n",
    "print(f\"  RÂ²:   {final_results['r2']:.4f}\")\n",
    "print(f\"{'='*40}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9163df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Training History\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax1 = axes[0]\n",
    "epochs = range(1, NUM_EPOCHS + 1)\n",
    "ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "ax1.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss (MSE)', fontsize=12)\n",
    "ax1.set_title('Training & Validation Loss', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# MAE curve\n",
    "ax2 = axes[1]\n",
    "ax2.plot(epochs, val_maes, 'g-', linewidth=2, marker='o')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('MAE (meters)', fontsize=12)\n",
    "ax2.set_title('Validation MAE Over Training', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('ResNet18 Training Progress - Camera to LiDAR Distance Prediction', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6513ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Predictions Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "targets = final_results['targets']\n",
    "predictions = final_results['predictions']\n",
    "\n",
    "# Predicted vs Actual\n",
    "ax1 = axes[0, 0]\n",
    "ax1.scatter(targets, predictions, alpha=0.5, s=20, c='blue')\n",
    "min_val, max_val = min(targets.min(), predictions.min()), max(targets.max(), predictions.max())\n",
    "ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect prediction')\n",
    "ax1.set_xlabel('Actual Distance (m)', fontsize=12)\n",
    "ax1.set_ylabel('Predicted Distance (m)', fontsize=12)\n",
    "ax1.set_title('Predicted vs Actual (Test Set)', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "ax2 = axes[0, 1]\n",
    "residuals = predictions - targets\n",
    "ax2.scatter(predictions, residuals, alpha=0.5, s=20, c='green')\n",
    "ax2.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax2.set_xlabel('Predicted Distance (m)', fontsize=12)\n",
    "ax2.set_ylabel('Residual (Pred - Actual)', fontsize=12)\n",
    "ax2.set_title('Residual Plot', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Error distribution\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(residuals, bins=30, color='purple', alpha=0.7, edgecolor='black')\n",
    "ax3.axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "ax3.axvline(x=residuals.mean(), color='orange', linestyle='-', lw=2, label=f'Mean: {residuals.mean():.3f}m')\n",
    "ax3.set_xlabel('Prediction Error (m)', fontsize=12)\n",
    "ax3.set_ylabel('Frequency', fontsize=12)\n",
    "ax3.set_title('Error Distribution', fontsize=14)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction timeline\n",
    "ax4 = axes[1, 1]\n",
    "frames = np.arange(len(targets))\n",
    "ax4.plot(frames, targets, 'b-', alpha=0.7, label='Actual', linewidth=1)\n",
    "ax4.plot(frames, predictions, 'r-', alpha=0.7, label='Predicted', linewidth=1)\n",
    "ax4.set_xlabel('Frame Index', fontsize=12)\n",
    "ax4.set_ylabel('Distance (m)', fontsize=12)\n",
    "ax4.set_title('Prediction Timeline (Test Session)', fontsize=14)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'ResNet18 Results - MAE: {final_results[\"mae\"]:.4f}m, RÂ²: {final_results[\"r2\"]:.4f}', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10e1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“‹ FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "DATASET:\n",
    "  - Source: Unitree Go1 Robot + RoboSense Helios-16 LiDAR\n",
    "  - Data: 100% REAL sensor measurements (NO synthetic data)\n",
    "  - Train: {len(train_dataset)} frames from 4 sessions\n",
    "  - Test: {len(test_dataset)} frames from 1 held-out session (Mlab)\n",
    "\n",
    "TASK:\n",
    "  - Cross-modal learning: Predict LiDAR distance from camera image\n",
    "  - Input: RGB camera image (1856x800 â†’ 224x224)\n",
    "  - Output: Mean LiDAR distance (meters)\n",
    "\n",
    "MODEL:\n",
    "  - Architecture: ResNet18 (pretrained on ImageNet)\n",
    "  - Training: {NUM_EPOCHS} epochs, batch size {BATCH_SIZE}\n",
    "  - Training time: {total_time:.1f} seconds\n",
    "\n",
    "RESULTS:\n",
    "  - Test MAE:  {final_results['mae']:.4f} meters\n",
    "  - Test RMSE: {final_results['rmse']:.4f} meters\n",
    "  - Test RÂ²:   {final_results['r2']:.4f}\n",
    "\n",
    "SAVED FIGURES:\n",
    "  - sample_images.png\n",
    "  - training_history.png\n",
    "  - prediction_results.png\n",
    "\"\"\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c3ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download generated figures\n",
    "from google.colab import files\n",
    "files.download('sample_images.png')\n",
    "files.download('training_history.png')\n",
    "files.download('prediction_results.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
